{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUFe5r3oZOOvEnuLogjv4v"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7LGElgtfd50",
        "outputId": "aa96600d-8e52-4664-afbb-61f00121c81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the required dependencies for the code snippet\n",
        "!pip install pandas scikit-learn numpy scipy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "\n",
        "# Label encoding for categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "data[' Label'] = label_encoder.fit_transform(data[' Label'])\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.drop([' Label'], axis=1)  # Features\n",
        "y = data[' Label']  # Labels\n",
        "\n",
        "# Handle NaNs and infinite values\n",
        "X = X.dropna()  # Drop rows with NaNs\n",
        "X = X.replace([float('inf'), -float('inf')], 1e12)  # Replace infinite values\n",
        "\n",
        "# Ensure 'y' has the same indices as 'X'\n",
        "y = y[X.index]\n",
        "\n",
        "# Reset indices to avoid misalignment\n",
        "X.reset_index(drop=True, inplace=True)\n",
        "y.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Check the lengths of features and labels\n",
        "print(\"Feature count:\", len(X))\n",
        "print(\"Label count:\", len(y))\n",
        "\n",
        "# Ensure consistent lengths\n",
        "if len(X) == len(y):\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Initialize the Random Forest model\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained model\n",
        "    joblib.dump(rf, 'random_forest_model.pkl')\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf.predict(X_test)\n",
        "\n",
        "    # Generate a classification report\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Generate a confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "else:\n",
        "    print(\"Feature and label lengths do not match.\")\n"
      ],
      "metadata": {
        "id": "SgiN-leYfjzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac012f94-cdc8-4bc6-9986-955bb3005d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature count: 225741\n",
            "Label count: 225741\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19417\n",
            "           1       1.00      1.00      1.00     25732\n",
            "\n",
            "    accuracy                           1.00     45149\n",
            "   macro avg       1.00      1.00      1.00     45149\n",
            "weighted avg       1.00      1.00      1.00     45149\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19417     0]\n",
            " [    8 25724]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scapy"
      ],
      "metadata": {
        "id": "MuWNm-LDfp3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e609f280-27e0-44be-9e91-15bd0121ec49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scapy in /usr/local/lib/python3.10/dist-packages (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scapy.all import sniff, TCP, Raw\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize variables to store calculated values\n",
        "dst_port = 0\n",
        "last_packet_time = 0\n",
        "\n",
        "# Function to process each packet and extract relevant information\n",
        "def process_packet(packet):\n",
        "    global dst_port, last_packet_time\n",
        "\n",
        "    try:\n",
        "        # Extract relevant fields from the packet\n",
        "        dst_port = packet[TCP].dport\n",
        "\n",
        "        # Calculate flow duration using packet timestamps\n",
        "        flow_duration = packet.time - last_packet_time\n",
        "\n",
        "        # Assuming you're interested in one-way traffic\n",
        "        total_fwd_packets = 1 if packet.haslayer(TCP) and packet[TCP].sport == src_port else 0\n",
        "        total_bwd_packets = 1 if packet.haslayer(TCP) and packet[TCP].dport == dst_port else 0\n",
        "\n",
        "        # Get total length of forward packets (assuming payload length)\n",
        "        total_fwd_length = len(packet[Raw].load) if packet.haslayer(Raw) else 0\n",
        "\n",
        "        # Assuming no backward packets in this example\n",
        "        total_bwd_length = 0\n",
        "\n",
        "        # Get maximum packet length\n",
        "        fwd_packet_length_max = len(packet)\n",
        "\n",
        "        # Get minimum packet length (assuming all packets have the same length)\n",
        "        fwd_packet_length_min = len(packet)\n",
        "\n",
        "        # Get mean packet length (assuming all packets have the same length)\n",
        "        fwd_packet_length_mean = len(packet)\n",
        "\n",
        "        # Assuming standard deviation is 0 since all packets have the same length\n",
        "        fwd_packet_length_std = 0\n",
        "\n",
        "        # Update last packet time for flow duration calculation in the next packet\n",
        "        last_packet_time = packet.time\n",
        "\n",
        "       # Generate network traffic data\n",
        "        network_data = pd.DataFrame(columns=[f'Destination Port_{i}' for i in range(1, num_cols + 1)],\n",
        "                            index=range(1, num_rows + 1),\n",
        "                            data=[[54865]*num_cols]*num_rows)\n",
        "\n",
        "        # Create a DataFrame for the packet data\n",
        "        packet_data = pd.DataFrame(data)\n",
        "\n",
        "        # Append the packet data to the CSV file\n",
        "        with open('network_traffic_data_5.csv', 'a') as f:\n",
        "            packet_data.to_csv(f, header=f.tell()==0, index=False)  # Append without header if file exists\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing packet: {e}\")\n",
        "\n",
        "# Initialize a variable to store the source port (you need to define this)\n",
        "src_port = 0\n",
        "\n",
        "# Sniff network traffic and process each packet\n",
        "sniff(prn=process_packet, count=10)  # Adjust the count as needed\n"
      ],
      "metadata": {
        "id": "8vQWgvEkfyrb",
        "outputId": "966f3e00-a1ed-4a3e-9b56-b94afb5bff9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sniffed: TCP:10 UDP:0 ICMP:0 Other:0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the number of rows and columns for the network traffic data\n",
        "num_rows = 100  # Specify the number of rows\n",
        "num_cols = 78   # Specify the number of Destination Port columns\n",
        "\n",
        "# Generate network traffic data\n",
        "network_data = pd.DataFrame(columns=[f'Destination Port_{i}' for i in range(1, num_cols + 1)],\n",
        "                            index=range(1, num_rows + 1),\n",
        "                            data=[[54865]*num_cols]*num_rows)\n",
        "\n",
        "# Save the generated network traffic data to a CSV file\n",
        "network_data.to_csv('/content/network_traffic_data_5.csv', index=False)\n",
        "\n",
        "print(\"Network traffic data saved to 'network_traffic_data.csv'.\")\n"
      ],
      "metadata": {
        "id": "9fA7Zlk2vVXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ed3640-1e65-483e-dbfa-c3bc9bf15d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network traffic data saved to 'network_traffic_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Load the trained Random Forest model\n",
        "rf_model = joblib.load('/content/random_forest_model.pkl')\n",
        "\n",
        "# Load the network traffic data from the CSV file\n",
        "network_data = pd.read_csv('/content/network_traffic_data_5.csv')\n",
        "\n",
        "# Preprocess the network traffic data (handle missing values, scale features)\n",
        "# You need to preprocess it in the same way as your training data (e.g., handle missing values, scale features)\n",
        "# Replace 'network_data' with the actual DataFrame containing your network traffic data\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "network_data_standardized = scaler.fit_transform(network_data)\n",
        "\n",
        "# Use the trained Random Forest model to predict whether the network traffic data packets are malicious\n",
        "predictions = rf_model.predict(network_data_standardized)\n",
        "\n",
        "# Generate alerts for malicious data packets\n",
        "for i, prediction in enumerate(predictions):\n",
        "    if prediction == 1:  # Assuming 1 represents a malicious label\n",
        "        print(\"Alert: Malicious network traffic detected at index\", i)\n",
        "        # You can further customize the alert generation based on your requirements\n"
      ],
      "metadata": {
        "id": "4khMCqsXvxry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Load the trained Random Forest model\n",
        "print(\"Loading the trained Random Forest model...\")\n",
        "rf_model = joblib.load('/content/random_forest_model.pkl')\n",
        "print(\"Random Forest model loaded successfully.\")\n",
        "\n",
        "# Load the network traffic data from the CSV file\n",
        "print(\"Loading the network traffic data...\")\n",
        "network_data = pd.read_csv('/content/network_traffic_data_5.csv')\n",
        "print(\"Network traffic data loaded successfully.\")\n",
        "\n",
        "# Preprocess the network traffic data\n",
        "print(\"Preprocessing the network traffic data...\")\n",
        "# Ensure that preprocessing steps are applied correctly\n",
        "scaler = StandardScaler()\n",
        "network_data_standardized = scaler.fit_transform(network_data)\n",
        "print(\"Network traffic data preprocessed successfully.\")\n",
        "\n",
        "# Use the trained Random Forest model to predict whether the network traffic data packets are malicious\n",
        "print(\"Making predictions...\")\n",
        "predictions = rf_model.predict(network_data_standardized)\n",
        "print(\"Predictions made successfully.\")\n",
        "\n",
        "# Generate alerts for malicious data packets\n",
        "print(\"Generating alerts for malicious data packets...\")\n",
        "malicious_count = 0\n",
        "for i, prediction in enumerate(predictions):\n",
        "    if prediction == 1:  # Assuming 1 represents a malicious label\n",
        "        print(\"Alert: Malicious network traffic detected at index\", i)\n",
        "        malicious_count += 1\n",
        "print(f\"Alert generation completed. Total {malicious_count} malicious data packets detected.\")\n"
      ],
      "metadata": {
        "id": "2S3u7TOjwUJu",
        "outputId": "fca346fe-c20f-4825-d01b-a386b901f7ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the trained Random Forest model...\n",
            "Random Forest model loaded successfully.\n",
            "Loading the network traffic data...\n",
            "Network traffic data loaded successfully.\n",
            "Preprocessing the network traffic data...\n",
            "Network traffic data preprocessed successfully.\n",
            "Making predictions...\n",
            "Predictions made successfully.\n",
            "Generating alerts for malicious data packets...\n",
            "Alert generation completed. Total 0 malicious data packets detected.\n"
          ]
        }
      ]
    }
  ]
}